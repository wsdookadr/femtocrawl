== Intro

This is a minimalistic dynamic page crawler accompanied by a variety of
tools used to produce sitemaps and some tools to deal with WARC files.

== Quick start

Clone femtocrawl and pull the latest femtocrawl image:

----
git clone https://github.com/wsdookadr/femtocrawl
cd femtocrawl
docker pull wsdookadr/femtocrawl
----

Create the required directories:

----
mkdir input/ warc/ zim/
----

Populate the input url list:

----
echo -e "https://lobste.rs\nhttps://news.ycombinator.com\nhttp://google.com\nhttp://mozilla.org" > input/list_urls.txt
----

Run the crawl

----
./bin/op.py --crawl
----

After the previous step, you'll see the following files:

----
user@garage3:~/zim-bench/femtocrawl$ ls -l warc/
total 1088
-rw-r--r-- 1 user user      84 Aug 22 01:53 1.urls
-rw-r--r-- 1 user user 1109534 Aug 22 01:53 1.warc
----

At this point, you can check the contents of the WARC using link:https://replayweb.page/[replayweb.page]

Now it's time for validation

----
./bin/op.py --validate
----

If invalid WARCs are reported, you can investigate further or exclude them by deleting them.

When all WARCs in the `warc/` directory are valid, you can join all the WARCs into `warc/big.zim`

----
./bin/op.py --join
----

At this point you can convert to ZIM

----
./bin/op.py --zim
----

And you can serve the archive locally at http://localhost:8083 like this:

----
./bin/op.py --kiwix
----

You can also use multiple of these switches at the same time.

== FAQ

=== How does it work?

More details about the way it works are in link:https://wsdookadr.github.io/posts/p8/[this blog post].

=== My host user UID/GID don't match the container UID/GID. What can I do?

For now, just change them in the Dockerfile and rebuild the docker image.

=== I want to change the browser profile, add extensions or userscripts, how do I do that?

Run the following on the host to get the Firefox profile

----
id=$(docker create wsdookadr/femtocrawl:latest)
docker cp $id:/home/user/ff ~/.mozilla/firefox/p1
docker rm -v $id
----

Start Firefox on the host with `firefox --profile ~/.mozilla/firefox/p1`.
Make any changes you want to it, close Firefox, zip the profile and place it in `data/ff.zip`
and rebuild the Docker image.

NOTE: The default ff profile comes with link:https://violentmonkey.github.io/api/gm/[violentmonkey] and link:https://github.com/gorhill/uBlock[uBlock].

=== I want to crawl a site that requires me to log in

See the previous item

=== I have some sites I'd like to crawl, what do I do?

On the host, do the following: place the urls you want crawled in a file,
one per line and run `bin/triage_new_links.sh` on that file, that will
produce two files `with_sitemap.txt` and `without_sitemap.txt`. Now
add the contents of those to `bin/gen_sitemap.sh` and run it. This will
produce `list_urls2.txt` which you can use as input for femtocrawl.

=== What kind of performance can I expect?

On a 56 Mbps connection with 10 urls and 29 seconds per batch, you can
crawl 29k urls per day.  The CPU usage is minimal.

=== What do I use this for?

Use-cases:

* building offline web archives
* website testing
* cross-testing different web archiving tools
* long-term news archiving


